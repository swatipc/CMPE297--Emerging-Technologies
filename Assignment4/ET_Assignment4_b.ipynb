{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ET_Assignment4_b.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTQSLtnel0mp"
      },
      "source": [
        "**Face Recognition using Siamese Networks with Meta Learning** \n",
        "\n",
        "The goal of this face recognition model is to understand whether the given two face images are same or different.\n",
        "\n",
        "Dataset used: [AT&T Database of Faces](https://www.kaggle.com/kasikrit/att-database-of-faces)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbshcxUBHe2q",
        "outputId": "d25c5719-7b8e-46b6-9428-cfaaa31a70c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import required libraries\n",
        "\n",
        "import re\n",
        "import keras\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import RMSprop\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EOdfP44Hwzk"
      },
      "source": [
        "#Function to read the images from dataset and convert them to a Numpy array\n",
        "\n",
        "def readImage(fileName, byteOrder='>'):\n",
        "    \n",
        "    # Read the image\n",
        "    with open(fileName, 'rb') as f:\n",
        "        buffer = f.read()\n",
        "    \n",
        "    # Extract header, width, height and maxval of the image\n",
        "    header, width, height, maxval = re.search(\n",
        "        b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
        "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
        "    # Convert the image to a Numpy array\n",
        "    img_to_nmpy = np.frombuffer(buffer,\n",
        "                            dtype='u1' if int(maxval) < 256 else byteOrder+'u2',\n",
        "                            count=int(width)*int(height),\n",
        "                            offset=len(header)\n",
        "                            ).reshape((int(height), int(width)))\n",
        "    return img_to_nmpy"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXkYy1y7HzZ1",
        "outputId": "0b7beb81-a4e9-4484-b096-e9e5f78dc21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "#Check the sample image\n",
        "Image.open(\"/content/drive/My Drive/Data/archive/s1/1.pgm\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PpmImagePlugin.PpmImageFile image mode=L size=92x112 at 0x7F44FF1A4CF8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzbmFQqpIQef"
      },
      "source": [
        "# Using readImage function read the image from dataset and convert it to a Numpy array\n",
        "\n",
        "img = readImage('/content/drive/My Drive/Data/archive/s1/1.pgm')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZWJTJOYIX1q",
        "outputId": "e01ca2ae-4cae-40ff-eb13-628c66b5255b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the shape of an retrieved image\n",
        "img.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 92)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFFzJarfIa9F"
      },
      "source": [
        "# Generate the data. \n",
        "\n",
        "size = 2\n",
        "totalSampleSize = 10000\n",
        "\n",
        "\n",
        "def getData(size, totalSampleSize):\n",
        "    img = readImage('/content/drive/My Drive/Data/archive/s' + str(1) + '/' + str(1) + '.pgm', 'rw+')\n",
        "    img = img[::size, ::size]\n",
        "    dim1 = img.shape[0]\n",
        "    dim2 = img.shape[1]\n",
        "    count = 0\n",
        "\n",
        "    #initialize the numpy array\n",
        "    xGenuinePair = np.zeros([totalSampleSize, 2, 1, dim1, dim2]) \n",
        "    yGenuine = np.zeros([totalSampleSize, 1])\n",
        "    \n",
        "    for i in range(30):\n",
        "        for j in range(int(totalSampleSize/30)):\n",
        "            ind_1 = 0\n",
        "            ind_2 = 0\n",
        "            while ind_1 == ind_2:\n",
        "                ind_1 = np.random.randint(10)\n",
        "                ind_2 = np.random.randint(10)\n",
        "            \n",
        "            # Read the images\n",
        "            img_1 = readImage('/content/drive/My Drive/Data/archive/s' + str(i+1) + '/' + str(ind_1 + 1) + '.pgm', 'rw+')\n",
        "            img_2 = readImage('/content/drive/My Drive/Data/archive/s' + str(i+1) + '/' + str(ind_2 + 1) + '.pgm', 'rw+')\n",
        "            \n",
        "            # Resize the images\n",
        "            img_1 = img_1[::size, ::size]\n",
        "            img_2 = img_2[::size, ::size]\n",
        "            \n",
        "            # Store the images to the numpy array\n",
        "            xGenuinePair[count, 0, 0, :, :] = img_1\n",
        "            xGenuinePair[count, 1, 0, :, :] = img_2\n",
        "            \n",
        "            # Assign label 1 to the genuine images\n",
        "            yGenuine[count] = 1\n",
        "            count += 1\n",
        "\n",
        "    # Repeat the same process fro imposite images\n",
        "    count = 0\n",
        "    xImpositePair = np.zeros([totalSampleSize, 2, 1, dim1, dim2])\n",
        "    yImposite = np.zeros([totalSampleSize, 1])\n",
        "    \n",
        "    for i in range(int(totalSampleSize/10)):\n",
        "        for j in range(10):\n",
        "            while True:\n",
        "                ind_1 = np.random.randint(40)\n",
        "                ind_2 = np.random.randint(40)\n",
        "                if ind_1 != ind_2:\n",
        "                    break\n",
        "                    \n",
        "            img_1 = readImage('/content/drive/My Drive/Data/archive/s' + str(ind_1+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
        "            img_2 = readImage('/content/drive/My Drive/Data/archive/s' + str(ind_2+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
        "\n",
        "            img_1 = img_1[::size, ::size]\n",
        "            img_2 = img_2[::size, ::size]\n",
        "\n",
        "            xImpositePair[count, 0, 0, :, :] = img_1\n",
        "            xImpositePair[count, 1, 0, :, :] = img_2\n",
        "\n",
        "            # Assign label 0 to imposite pair of images\n",
        "            yImposite[count] = 0\n",
        "            count += 1\n",
        "            \n",
        "    # Concatenate the genuine pairs and imposite pair to get the whole data\n",
        "    X = np.concatenate([xGenuinePair, xImpositePair], axis=0)/255\n",
        "    Y = np.concatenate([yGenuine, yImposite], axis=0)\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiW9GcpxIh6i"
      },
      "source": [
        "# Generate the data and store in X and Y variables\n",
        "\n",
        "X, Y = getData(size, totalSampleSize)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jm7OvoCIkcY",
        "outputId": "0855e519-b303-4231-cc05-21c46a67d8f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the shape of input images\n",
        "X.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 2, 1, 56, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuoFyiphI53Y",
        "outputId": "17ae1abe-a1e0-4fa9-d509-e1b951cab72f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check the shape of Y\n",
        "Y.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm8xjZzMI8be"
      },
      "source": [
        "# Split the data to train and test\n",
        "\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=.30)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSxc6uA1I9DK"
      },
      "source": [
        "# Build the Siamese Network with 2 layer Convolutional network as a base network which would be used for feature extraction from images\n",
        "\n",
        "def buildBaseNetwork(inputShape):\n",
        "    \n",
        "    seq = Sequential()\n",
        "    nb_filter = [6, 12]\n",
        "    kernelSize = 3\n",
        "    \n",
        "    # Conv layer 1\n",
        "    seq.add(Convolution2D(nb_filter[0], kernelSize, kernelSize, input_shape=inputShape,\n",
        "                          padding='valid', data_format='channels_first'))\n",
        "    seq.add(Activation('relu'))\n",
        "    seq.add(MaxPooling2D(pool_size=(2, 2)))  \n",
        "    seq.add(Dropout(.25))\n",
        "    \n",
        "    # Conv layer 2\n",
        "    seq.add(Convolution2D(nb_filter[1], kernelSize, kernelSize, padding='valid', data_format='channels_first'))\n",
        "    seq.add(Activation('relu'))\n",
        "    seq.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first')) \n",
        "    seq.add(Dropout(.25))\n",
        "\n",
        "    # Flatten the layers\n",
        "    seq.add(Flatten())\n",
        "    seq.add(Dense(128, activation='relu'))\n",
        "    seq.add(Dropout(0.1))\n",
        "    seq.add(Dense(50, activation='relu'))\n",
        "    return seq"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_CTp5rYJCAV"
      },
      "source": [
        "# Image pair to feed to the base network to get the feature vectors\n",
        "\n",
        "input_Dim = xTrain.shape[2:]\n",
        "img_A = Input(shape=input_Dim)\n",
        "img_B = Input(shape=input_Dim)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eUteld5JEeL"
      },
      "source": [
        "base_network = buildBaseNetwork(input_Dim)\n",
        "feat_vecs_A = base_network(img_A)\n",
        "feat_vecs_B = base_network(img_B)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x526GebJHW8"
      },
      "source": [
        "# Fuunctions to determine the distancce between the feature vectors\n",
        "\n",
        "def euclideanDistance(vects):\n",
        "    x, y = vects\n",
        "    dist = K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "    return dist\n",
        "\n",
        "\n",
        "def euclDistOutputShape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    eu_dist_op_shape = (shape1[0], 1)\n",
        "    return eu_dist_op_shape"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llu7XeqqJKQt"
      },
      "source": [
        "distance = Lambda(euclideanDistance, output_shape=euclDistOutputShape)([feat_vecs_A, feat_vecs_B])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTuz0c-fJLE2"
      },
      "source": [
        "# Define number of epochs and optimization function to be used\n",
        "epochs = 30\n",
        "rms = RMSprop()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwav2-PVJOnn"
      },
      "source": [
        "# Define the model\n",
        "model = Model([img_A, img_B],distance)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4spbYeqbJQ0l"
      },
      "source": [
        "# Loss function\n",
        "\n",
        "def contrastiveLoss(yTrue, yPred):\n",
        "    margin = 1\n",
        "    loss = K.mean(yTrue * K.square(yPred) + (1 - yTrue) * K.square(K.maximum(margin - yPred, 0)))\n",
        "    return loss"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utt-OQCbJTXj"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(loss=contrastiveLoss, optimizer=rms)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hu4sE3JJTmG"
      },
      "source": [
        "img_1 = xTrain[:, 0]\n",
        "img_2 = xTrain[:, 1]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrkiWUcSJXYy",
        "outputId": "d8b4b826-af9e-42a2-905d-f3f9767e0ee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the model\n",
        "\n",
        "model.fit([img_1, img_2], yTrain, validation_split=.25,\n",
        "          batch_size=128, verbose=2, epochs=epochs)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "83/83 - 1s - loss: 0.1614 - val_loss: 0.1278\n",
            "Epoch 2/30\n",
            "83/83 - 0s - loss: 0.1583 - val_loss: 0.1281\n",
            "Epoch 3/30\n",
            "83/83 - 0s - loss: 0.1522 - val_loss: 0.1159\n",
            "Epoch 4/30\n",
            "83/83 - 0s - loss: 0.1510 - val_loss: 0.1244\n",
            "Epoch 5/30\n",
            "83/83 - 0s - loss: 0.1472 - val_loss: 0.1497\n",
            "Epoch 6/30\n",
            "83/83 - 1s - loss: 0.1448 - val_loss: 0.1243\n",
            "Epoch 7/30\n",
            "83/83 - 1s - loss: 0.1421 - val_loss: 0.1060\n",
            "Epoch 8/30\n",
            "83/83 - 0s - loss: 0.1405 - val_loss: 0.1154\n",
            "Epoch 9/30\n",
            "83/83 - 0s - loss: 0.1368 - val_loss: 0.1248\n",
            "Epoch 10/30\n",
            "83/83 - 0s - loss: 0.1349 - val_loss: 0.1146\n",
            "Epoch 11/30\n",
            "83/83 - 0s - loss: 0.1335 - val_loss: 0.1043\n",
            "Epoch 12/30\n",
            "83/83 - 1s - loss: 0.1324 - val_loss: 0.1053\n",
            "Epoch 13/30\n",
            "83/83 - 1s - loss: 0.1310 - val_loss: 0.0961\n",
            "Epoch 14/30\n",
            "83/83 - 0s - loss: 0.1308 - val_loss: 0.0950\n",
            "Epoch 15/30\n",
            "83/83 - 0s - loss: 0.1296 - val_loss: 0.0977\n",
            "Epoch 16/30\n",
            "83/83 - 0s - loss: 0.1288 - val_loss: 0.0968\n",
            "Epoch 17/30\n",
            "83/83 - 0s - loss: 0.1272 - val_loss: 0.0885\n",
            "Epoch 18/30\n",
            "83/83 - 0s - loss: 0.1256 - val_loss: 0.0974\n",
            "Epoch 19/30\n",
            "83/83 - 0s - loss: 0.1242 - val_loss: 0.0920\n",
            "Epoch 20/30\n",
            "83/83 - 0s - loss: 0.1259 - val_loss: 0.0987\n",
            "Epoch 21/30\n",
            "83/83 - 0s - loss: 0.1214 - val_loss: 0.1042\n",
            "Epoch 22/30\n",
            "83/83 - 0s - loss: 0.1216 - val_loss: 0.0967\n",
            "Epoch 23/30\n",
            "83/83 - 1s - loss: 0.1206 - val_loss: 0.0886\n",
            "Epoch 24/30\n",
            "83/83 - 0s - loss: 0.1215 - val_loss: 0.0847\n",
            "Epoch 25/30\n",
            "83/83 - 0s - loss: 0.1188 - val_loss: 0.1014\n",
            "Epoch 26/30\n",
            "83/83 - 0s - loss: 0.1186 - val_loss: 0.0844\n",
            "Epoch 27/30\n",
            "83/83 - 0s - loss: 0.1184 - val_loss: 0.0855\n",
            "Epoch 28/30\n",
            "83/83 - 0s - loss: 0.1161 - val_loss: 0.0880\n",
            "Epoch 29/30\n",
            "83/83 - 0s - loss: 0.1171 - val_loss: 0.0904\n",
            "Epoch 30/30\n",
            "83/83 - 0s - loss: 0.1146 - val_loss: 0.0947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f44a215bef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Kp5lxtI6yLd"
      },
      "source": [
        "# Make predictions\n",
        "\n",
        "pred = model.predict([xTest[:, 0], xTest[:, 1]])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STB5pd3dy0Nu"
      },
      "source": [
        "# Function to determine accuracy of model\n",
        "def computeAccuracy(predictions, labels):\n",
        "    accuracy = labels[predictions.ravel() < 0.5].mean()\n",
        "    return accuracy"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4qoZ8uazDNU",
        "outputId": "7f27d914-0c39-4e8f-99dc-c6d1ab46fb4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check accuracy of the model\n",
        "computeAccuracy(pred, yTest)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.828646748681898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm9c3b0h1i8N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}