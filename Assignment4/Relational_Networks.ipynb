{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Relational_Networks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq1eu8h_TrG4"
      },
      "source": [
        "# Import libraries\n",
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6-R2AW2TyDW"
      },
      "source": [
        "# Generate data points\n",
        "\n",
        "class_A = np.random.rand(1000,18)\n",
        "\n",
        "Class_B = np.random.rand(1000,18)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saI-ticCUAzh"
      },
      "source": [
        "# Combine the classes to generate dataset\n",
        "dataset = np.vstack([class_A, Class_B])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9UrmxpqUI-O"
      },
      "source": [
        "# set the labels\n",
        "labels = np.vstack([np.ones((len(class_A),1)),np.zeros((len(Class_B),1))])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45nb6ekLUUEw",
        "outputId": "a99d0958-06ab-49aa-fedf-daa6176bab2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check dataset shape\n",
        "dataset.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfw1mvU_UZEC",
        "outputId": "78681bd5-71d9-4795-dabd-389fe32a309f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Check label shape\n",
        "labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFF7lT6QUfmj"
      },
      "source": [
        "# Define placeholder for the support set and query set\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "x_i = tf.placeholder(tf.float32, [None, 9])\n",
        "x_j = tf.placeholder(tf.float32, [None, 9])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmECpPRiUsoY"
      },
      "source": [
        "# Define placeholder for label\n",
        "y = tf.placeholder(tf.float32, [None, 1])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y__ccFmVVy8l"
      },
      "source": [
        "# Define embedding function which with learn embeddings from query set and support set.\n",
        "def embedding_function(x):\n",
        "    weight = tf.Variable(tf.truncated_normal([9,1]))\n",
        "    bias = tf.Variable(tf.truncated_normal([1]))    \n",
        "    a = (tf.nn.xw_plus_b(x,weight,bias))\n",
        "    return tf.nn.relu(a)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaGJvG7zWdBa"
      },
      "source": [
        "#Compute embedding for support set\n",
        "f_Xi = embedding_function(x_i)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n95a1dZ7Wrdz"
      },
      "source": [
        "# Compute embedding for Query set\n",
        "f_Xj = embedding_function(x_j)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXfBmEfBW1O8"
      },
      "source": [
        "# Combine support set and query set features\n",
        "Z = tf.concat([f_Xi,f_Xj],axis=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFt4RWDPZONd"
      },
      "source": [
        "# Define Relational function\n",
        "def relational_function(x):\n",
        "    w_1 = tf.Variable(tf.truncated_normal([2,3]))\n",
        "    b_1 = tf.Variable(tf.truncated_normal([3]))\n",
        "    \n",
        "    w_2 = tf.Variable(tf.truncated_normal([3,5]))\n",
        "    b_2 = tf.Variable(tf.truncated_normal([5]))\n",
        "    \n",
        "    w_3 = tf.Variable(tf.truncated_normal([5,1]))\n",
        "    b_3 = tf.Variable(tf.truncated_normal([1]))\n",
        "    \n",
        "    #layer1\n",
        "    z_1 = (tf.nn.xw_plus_b(x,w_1,b_1))\n",
        "    a_1 = tf.nn.relu(z_1)\n",
        "    \n",
        "    #layer2\n",
        "    z_2 = tf.nn.xw_plus_b(a_1,w_2,b_2)\n",
        "    a_2 = tf.nn.relu(z_2)\n",
        "    \n",
        "    #layer3\n",
        "    z_3 = tf.nn.xw_plus_b(z_2,w_3,b_3)\n",
        "\n",
        "    #output\n",
        "    y = tf.nn.sigmoid(z_3)\n",
        "    \n",
        "    return y"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMGRciPeZ8G-"
      },
      "source": [
        "# pass feature vector\n",
        "relational_scores = relational_function(Z)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xakzUTaba29t"
      },
      "source": [
        "# Define loss function as a mean sequered error between label and relational score\n",
        "loss_function = tf.reduce_mean(tf.squared_difference(relational_scores,y))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGWVLV3FbYRo"
      },
      "source": [
        "#Loss minimization\n",
        "optimizer = tf.train.AdamOptimizer(0.1)\n",
        "train = optimizer.minimize(loss_function)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzgpAmEcbkAJ"
      },
      "source": [
        "# Start tensorflow session\n",
        "session = tf.InteractiveSession()\n",
        "session.run(tf.global_variables_initializer())"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRu15dVLb-7z",
        "outputId": "13b3eaa3-85fe-4515-b397-f15ecaa147af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the relational network\n",
        "for episode in range(1000):\n",
        "    _, loss_value = session.run([train, loss_function], \n",
        "                             feed_dict={x_i:dataset[:,0:9]+np.random.randn(*np.shape(dataset[:,0:9]))*0.05,\n",
        "                                        x_j:dataset[:,9:]+np.random.randn(*np.shape(dataset[:,9:]))*0.05,\n",
        "                                        y:label})\n",
        "    if episode % 100 == 0:\n",
        "        print(\"Episode {}: loss {:.3f} \".format(episode, loss_value))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0: loss 0.330 \n",
            "Episode 100: loss 0.250 \n",
            "Episode 200: loss 0.250 \n",
            "Episode 300: loss 0.250 \n",
            "Episode 400: loss 0.250 \n",
            "Episode 500: loss 0.250 \n",
            "Episode 600: loss 0.250 \n",
            "Episode 700: loss 0.250 \n",
            "Episode 800: loss 0.250 \n",
            "Episode 900: loss 0.250 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7F0-PKgcTFi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}